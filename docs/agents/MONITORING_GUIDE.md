# ğŸ” Monitoring AI/LLM - Guide Complet

## Vue d'Ensemble des Solutions

### ğŸ“Š Architecture de Monitoring RecommandÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITORING STACK                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   GRAFANA    â”‚    â”‚  LANGSMITH   â”‚    â”‚   DASHBOARD  â”‚ â”‚
â”‚  â”‚   (Metrics)  â”‚    â”‚  (LLM Trace) â”‚    â”‚   (Real-time)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                   â”‚                    â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            PROMETHEUS (MÃ©triques)                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜ â”‚
â”‚                                                          â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â” â”‚
â”‚  â”‚        AI PROVIDERS (Claude Haiku/Sonnet)              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. âœ… Grafana (DÃ©jÃ  ConfigurÃ©)

### MÃ©triques Actuelles Disponibles

**Port** : http://localhost:3001
**Datasource** : Prometheus (PBFA97CFB590B2093)

#### Dashboards Existants
- âœ… Triage Stage 1 Health
- âœ… Triage Stage 2 - NLP Pipeline
- âœ… Market Health
- âœ… Feature Store Health
- âœ… Pipeline Health
- âœ… Quick Start

#### MÃ©triques AI Disponibles

```promql
# MÃ©triques du dashboard custom AI (port 8010)
ai_completions_total{provider="anthropic", model="claude-haiku-4-5-20251001"}
ai_completions_total{provider="anthropic", model="claude-sonnet-4-5-20250929"}

# CoÃ»t total
ai_cost_usd_total{provider="anthropic"}

# Latence
ai_latency_seconds{provider="anthropic", tier="fast"}
ai_latency_seconds{provider="anthropic", tier="medium"}

# RequÃªtes actives
ai_active_requests
```

### CrÃ©er un Dashboard AI dans Grafana

**Panels recommandÃ©s :**
1. **Completions Rate** (completions/min)
2. **Token Usage** (tokens/sec)
3. **Cost** ($/hour)
4. **Latency P95** (ms)
5. **Error Rate** (%)
6. **Model Distribution** (pie chart)

---

## 2. ğŸ”¥ LangSmith (RecommandÃ© pour LLMs)

### Pourquoi LangSmith ?

**Avantages sur Grafana pour les LLMs :**
- âœ… Trace **chaque prompt/rÃ©ponse** en dÃ©tail
- âœ… Debug interactif des conversations
- âœ… Evaluation de qualitÃ© des rÃ©ponses
- âœ… Datasets pour testing
- âœ… Comparaison de modÃ¨les
- âœ… CoÃ»t par conversation
- âœ… UI spÃ©cialisÃ©e pour LLMs

### Installation

```bash
pip install langsmith langchain
```

### Configuration

**1. CrÃ©er un compte** : https://smith.langchain.com

**2. Obtenir API Key** : Settings â†’ API Keys

**3. Configurer `.env`** :
```bash
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=ls-...
LANGCHAIN_PROJECT=trading-platform-prod
```

### IntÃ©gration avec le Code Existant

#### Option A : Wrapper Automatique (Simple)

```python
# Dans src/agents/providers/anthropic_provider.py
from langsmith import traceable
from langsmith.run_helpers import trace_as_chain_group

class AnthropicProvider(BaseProvider):
    
    @traceable(
        run_type="llm",
        name="claude_completion",
        project_name="trading-platform"
    )
    async def complete(
        self,
        request: CompletionRequest,
        tier: ModelTier = ModelTier.MEDIUM
    ) -> CompletionResponse:
        """Execute completion using Claude - traced by LangSmith"""
        
        # Tout le code existant reste identique
        # LangSmith capture automatiquement :
        # - Input (prompt)
        # - Output (response)
        # - Latency
        # - Model
        # - Tokens
        # - Cost
        
        # ... code existant ...
```

#### Option B : IntÃ©gration LangChain ComplÃ¨te

```python
# src/agents/langchain_wrapper.py
from langchain_anthropic import ChatAnthropic
from langchain.callbacks.tracers import LangChainTracer
from langchain.schema import HumanMessage, SystemMessage

class LangChainClaudeProvider:
    """Wrapper LangChain pour Claude avec tracing automatique"""
    
    def __init__(self, config):
        self.haiku = ChatAnthropic(
            model="claude-haiku-4-5-20251001",
            anthropic_api_key=config.api_key,
            temperature=0.3,
        )
        
        self.sonnet = ChatAnthropic(
            model="claude-sonnet-4-5-20250929",
            anthropic_api_key=config.api_key,
            temperature=0.3,
        )
        
        # LangSmith tracer (automatique si env vars configurÃ©es)
        self.tracer = LangChainTracer(project_name="trading-platform")
    
    async def complete(self, request: CompletionRequest, tier: ModelTier):
        """Completion with automatic LangSmith tracing"""
        
        model = self.haiku if tier == ModelTier.FAST else self.sonnet
        
        messages = []
        if request.system_prompt:
            messages.append(SystemMessage(content=request.system_prompt))
        messages.append(HumanMessage(content=request.prompt))
        
        # Appel automatiquement tracÃ© par LangSmith
        response = await model.ainvoke(
            messages,
            config={"callbacks": [self.tracer]}
        )
        
        return response
```

### Utilisation

Une fois configurÃ©, **chaque appel est automatiquement tracÃ©** :

```python
# Votre code reste identique
response = await provider.complete(request, tier=ModelTier.FAST)

# Mais LangSmith capture tout automatiquement !
# Voir sur : https://smith.langchain.com/projects/<your-project>
```

### Dashboard LangSmith

**AccÃ¨s** : https://smith.langchain.com

**FonctionnalitÃ©s** :
- ğŸ“Š Vue d'ensemble des runs
- ğŸ” Recherche par prompt/rÃ©ponse
- ğŸ“ˆ MÃ©triques (latency, cost, tokens)
- ğŸ› Debug de conversations complÃ¨tes
- â­ Feedback/rating des rÃ©ponses
- ğŸ“ Datasets pour testing
- ğŸ”¬ Evaluation automatique

---

## 3. ğŸ¨ LangFlow (UI Builder)

### C'est Quoi ?

**Interface visuelle** pour crÃ©er des workflows LangChain sans code :
- Drag & drop de composants
- Connexion visuelle LLM â†’ Prompt â†’ Output
- Export en Python
- Utile pour prototyper rapidement

### Installation

```bash
pip install langflow
langflow run
```

**AccÃ¨s** : http://localhost:7860

### Cas d'Usage

**Bon pour** :
- âœ… Prototypage rapide
- âœ… DÃ©monstrations
- âœ… Tests de prompts
- âœ… Non-dÃ©veloppeurs

**Moins bon pour** :
- âŒ Production Ã  grande Ã©chelle
- âŒ Logique complexe
- âŒ IntÃ©gration avec systÃ¨me existant

**Recommandation** : Utiliser pour prototyper, puis coder en Python.

---

## 4. ğŸ¯ Recommandation Finale

### Stack de Monitoring IdÃ©al

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INFRASTRUCTURE METRICS (Grafana + Prometheus)          â”‚
â”‚  - CPU, RAM, Disk                                       â”‚
â”‚  - Pipeline throughput                                  â”‚
â”‚  - Service health                                       â”‚
â”‚  â†’ Dashboard : http://localhost:3001                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         +
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI METRICS (Dashboard Custom)                          â”‚
â”‚  - Completions count                                    â”‚
â”‚  - Token usage                                          â”‚
â”‚  - Cost tracking                                        â”‚
â”‚  - Model distribution                                   â”‚
â”‚  â†’ Dashboard : http://localhost:8010                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         +
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM TRACING (LangSmith)                               â”‚
â”‚  - Detailed prompts/responses                           â”‚
â”‚  - Conversation flows                                   â”‚
â”‚  - Quality evaluation                                   â”‚
â”‚  - A/B testing                                          â”‚
â”‚  â†’ Dashboard : https://smith.langchain.com              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplÃ©mentation Progressive

**Phase 1 : Actuellement âœ…**
- Grafana (metrics infra)
- Dashboard custom (metrics AI basiques)

**Phase 2 : Ajouter LangSmith (RecommandÃ©)**
- Tracing dÃ©taillÃ© des LLMs
- Debug et evaluation
- Datasets de test

**Phase 3 : Optimisation**
- Exporter mÃ©triques LangSmith â†’ Prometheus
- Dashboard unifiÃ© dans Grafana
- Alertes automatiques

---

## 5. ğŸš€ ImplÃ©mentation LangSmith (Quick Start)

### Ã‰tape 1 : Installation

```bash
cd /home/leox7/trading-platform
source venv/bin/activate
pip install langsmith langchain-anthropic
```

### Ã‰tape 2 : Configuration

Ajouter Ã  `.env` :
```bash
# LangSmith Configuration
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=ls-xxx  # Obtenir sur smith.langchain.com
LANGCHAIN_PROJECT=trading-platform-prod
```

### Ã‰tape 3 : Modifier le Provider

```bash
# Ajouter le dÃ©corateur @traceable
nano src/agents/providers/anthropic_provider.py
```

### Ã‰tape 4 : VÃ©rifier

```python
# Test
python examples/test_ai_providers.py

# Voir les traces sur :
# https://smith.langchain.com/projects/trading-platform-prod
```

---

## 6. ğŸ“Š MÃ©triques Disponibles par Outil

| MÃ©trique | Grafana | Dashboard Custom | LangSmith |
|----------|---------|------------------|-----------|
| **Infrastructure** | âœ… | âŒ | âŒ |
| CPU/RAM/Network | âœ… | âŒ | âŒ |
| Service Health | âœ… | âŒ | âŒ |
| **AI - AgrÃ©gats** | âš ï¸ | âœ… | âœ… |
| Completions/min | âš ï¸ | âœ… | âœ… |
| Token usage | âš ï¸ | âœ… | âœ… |
| Cost tracking | âš ï¸ | âœ… | âœ… |
| Latency P95 | âš ï¸ | âœ… | âœ… |
| **AI - DÃ©tails** | âŒ | âš ï¸ | âœ… |
| Prompt complet | âŒ | âš ï¸ | âœ… |
| RÃ©ponse complÃ¨te | âŒ | âš ï¸ | âœ… |
| Conversation flow | âŒ | âŒ | âœ… |
| Evaluation qualitÃ© | âŒ | âŒ | âœ… |
| A/B testing | âŒ | âŒ | âœ… |
| Datasets | âŒ | âŒ | âœ… |

**LÃ©gende** :
- âœ… SupportÃ© nativement
- âš ï¸ Possible mais limitÃ©
- âŒ Non supportÃ©

---

## 7. ğŸ’° CoÃ»ts

| Outil | CoÃ»t | Limites |
|-------|------|---------|
| **Grafana** | Gratuit (self-hosted) | Aucune |
| **Prometheus** | Gratuit (self-hosted) | Aucune |
| **Dashboard Custom** | Gratuit | Aucune |
| **LangSmith** | Gratuit : 5K traces/mois | Puis $39-99/mois |
| **LangFlow** | Gratuit (self-hosted) | Aucune |

---

## 8. ğŸ“ Ressources

### Documentation
- **Grafana** : https://grafana.com/docs/
- **LangSmith** : https://docs.smith.langchain.com/
- **LangChain** : https://python.langchain.com/docs/
- **LangFlow** : https://docs.langflow.org/

### Tutoriels
- LangSmith Quick Start : https://docs.smith.langchain.com/old/tracing/quick_start
- Grafana AI Dashboard : https://grafana.com/grafana/dashboards/

---

## âœ… Conclusion

**Pour votre projet** :

1. **Garder Grafana** pour l'infra et le pipeline
2. **Garder Dashboard Custom** (http://localhost:8010) pour metrics AI basiques
3. **Ajouter LangSmith** pour tracing dÃ©taillÃ© des LLMs
4. **Skip LangFlow** (pas nÃ©cessaire, vous codez dÃ©jÃ )

**Installation recommandÃ©e** :
```bash
# 1. Installer LangSmith
pip install langsmith langchain-anthropic

# 2. Configurer .env (ajouter LANGCHAIN_*)

# 3. Ajouter @traceable aux providers

# 4. Profiter ! ğŸ‰
```

**Vous aurez alors** :
- ğŸ“Š Grafana : MÃ©triques systÃ¨me (dÃ©jÃ  âœ…)
- ğŸ¤– Dashboard : MÃ©triques AI temps rÃ©el (dÃ©jÃ  âœ…)
- ğŸ” LangSmith : Tracing dÃ©taillÃ© LLM (Ã  ajouter)
