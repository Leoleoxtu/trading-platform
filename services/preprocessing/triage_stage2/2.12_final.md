# Triage Stage 2 - NLP Enrichment Service

## Overview

Triage Stage 2 enriches Stage 1 events with advanced NLP analysis, providing:
- **spaCy NER**: Named entity extraction (ORG, PERSON, MONEY, PERCENT, etc.)
- **FinBERT**: Financial sentiment analysis with confidence scores
- **Explainable Scoring**: 0-100 composite score with detailed breakdown
- **Adaptive Thresholds**: Priority assignment (P0-P3) adjusted by market and load regimes
- **Quality Flags**: Comprehensive event quality assessment

## Architecture

```
INPUT (Kafka):
├─ events.stage1.fast.v1      (high-priority Stage 1 events)
└─ events.stage1.standard.v1  (standard-priority Stage 1 events)

NLP PIPELINE:
├─ spaCy NER (en_core_web_sm, fr_core_news_sm)
├─ FinBERT Sentiment (ProsusAI/finbert)
├─ Ticker Validation (whitelist-based)
├─ Scoring Engine (5 components)
├─ Regime Detection (market + load)
└─ Adaptive Threshold Calculation

OUTPUT (Kafka):
├─ events.triaged.v1          (successfully triaged events, 6 partitions)
└─ events.triaged.dlq.v1      (failed events, 1 partition)

OBSERVABILITY:
├─ Prometheus metrics (port 8007)
└─ Health endpoint (/health)
```

## Configuration

### Environment Variables
- `KAFKA_BOOTSTRAP_SERVERS`: Kafka brokers (default: localhost:9092)
- `REDIS_URL`: Redis connection string (default: redis://localhost:6379)
- `CONFIG_PATH`: Path to triage_stage2.yaml (default: config/triage_stage2.yaml)
- `TICKERS_WHITELIST`: Path to tickers CSV (default: config/tickers_whitelist.csv)
- `HEALTH_PORT`: Health/metrics port (default: 8007)
- `PIPELINE_VERSION`: Version identifier (default: triage-stage2.v1.0)
- `LOG_LEVEL`: Logging level (default: INFO)

### Configuration File (triage_stage2.yaml)
Located at `/etc/triage_stage2.yaml` in container:
- **keywords**: Impact categories (earnings, regulation, macro, security, merger, bankruptcy)
- **source_quality**: Reliability/noise mapping per source
- **scoring.weights**: Component weights (keywords: 30, source: 25, ticker: 20, entities: 10, sentiment: 15)
- **thresholds**: Baseline (P0=80, P1=60, P2=40) + regime adjustments
- **market_regime**: VIX thresholds (STRESS≥25, CALM<12)
- **load_regime**: Consumer lag, latency, DLQ rate thresholds
- **nlp**: spaCy models, FinBERT config, max_text_length

### Ticker Whitelist (tickers_whitelist.csv)
CSV file with validated ticker symbols. Only tickers in this list will contribute to scoring.

## Scoring System

**Total Score**: 0-100 points from 5 components:

### 1. Keywords (0-30 points)
Matches high-impact terms in 6 categories:
- **earnings**: earnings, revenue, profit, guidance, EPS
- **regulation**: SEC, Fed, CFTC, investigation, fine
- **macro**: inflation, GDP, unemployment, interest rate
- **security**: breach, hack, cybersecurity, ransomware
- **merger**: merger, acquisition, M&A, buyout
- **bankruptcy**: bankruptcy, Chapter 11, default

Each category match: +5 points  
Weak keywords (rumor, might, could): +1 point

### 2. Source Quality (0-25 points)
Based on historical reliability:
- **bloomberg**: 0.95 → 23.75 points
- **reuters**: 0.90 → 22.5 points
- **reddit/wallstreetbets**: 0.50 → 12.5 points

### 3. Ticker Confidence (0-20 points)
Average confidence of validated tickers:
- **Inherited** from Stage 1: 0.95
- **Entity match** (ORG → ticker): 0.75
- **Regex** extraction: 0.65

### 4. Entity Strength (0-10 points)
Quality and quantity of named entities:
- **ORG**: 3 points × confidence
- **PERSON**: 2 points × confidence
- **MONEY**: 2 points × confidence
- **PERCENT**: 1.5 points × confidence

### 5. Sentiment Impact (0-15 points)
FinBERT sentiment magnitude × confidence:
- Score range: [-1, 1]
- Strong sentiment (|score| ≥ 0.5): Bonus
- Low confidence (< 0.3): Penalty (-5 points)

## Priority Assignment

### Baseline Thresholds
- **P0** (critical): ≥ 80 points
- **P1** (high): ≥ 60 points
- **P2** (medium): ≥ 40 points
- **P3** (low): < 40 points

### Regime Adjustments

**Market Regime** (VIX-based):
- **STRESS** (VIX ≥ 25): Lower thresholds by 10 → More P0/P1
- **CALM** (VIX < 12): Raise thresholds by 5 → Fewer P0/P1
- **NORMAL**: No adjustment

**Load Regime** (pipeline metrics):
- **HIGH_LOAD**: Raise thresholds by 5 → Reduce downstream load
- **NORMAL_LOAD**: No adjustment
- **LOW_LOAD**: Lower thresholds by 3 → Process more events

### Example
```
Event score: 78
Market regime: STRESS → P0 threshold: 80 - 10 = 70
Load regime: NORMAL → P0 threshold: 70 + 0 = 70
Result: 78 ≥ 70 → P0
```

## Triage Reasons (Explainability)

Each event includes a list of reasons explaining the triage decision:

**High Impact**:
- `KEYWORD_EARNINGS`, `KEYWORD_REGULATION`, `KEYWORD_MACRO`, etc.
- `HIGH_SOURCE_QUALITY` (reliability ≥ 0.85)
- `HAS_VALID_TICKER`
- `STRONG_ENTITIES` (score ≥ 7)
- `STRONG_SENTIMENT` (|score| ≥ 0.5)
- `STRESS_REGIME_BOOST`

**Low Impact**:
- `NO_TICKER`
- `LOW_SOURCE_QUALITY` (reliability ≤ 0.50)
- `NER_EMPTY` (no entities)
- `WEAK_ENTITIES` (score ≤ 2)
- `WEAK_SENTIMENT` (|score| < 0.5)
- `LOW_SENTIMENT_CONF` (confidence < 0.3)
- `SHORT_TEXT`, `LONG_TEXT`
- `HIGH_LOAD_PENALTY`

## Running Locally

### Prerequisites
- Python 3.12+
- Kafka (Redpanda)
- Redis
- spaCy models: `python -m spacy download en_core_web_sm fr_core_news_sm`

### Install Dependencies
```bash
pip install -r requirements.txt
```

### Run Service
```bash
export KAFKA_BOOTSTRAP_SERVERS=localhost:9092
export REDIS_URL=redis://localhost:6379
export CONFIG_PATH=config/triage_stage2.yaml
export TICKERS_WHITELIST=config/tickers_whitelist.csv
export HEALTH_PORT=8007

python app.py
```

### Check Health
```bash
curl http://localhost:8007/health
curl http://localhost:8007/metrics
```

## Running with Docker

### Build Image
```bash
docker compose --profile apps build triage-stage2
```

### Start Service
```bash
docker compose --profile apps up -d triage-stage2
```

### Check Logs
```bash
docker logs triage-stage2 -f
```

### Stop Service
```bash
docker compose stop triage-stage2
```

## Testing

### Integration Tests
```bash
# Ensure services are running
docker compose --profile apps up -d

# Run tests
python tests/integration/test_triage_stage2.py --bootstrap-servers localhost:9092

# Expected: 5/5 events processed and validated
```

### Manual Testing
```bash
# 1. Publish test event to Stage 1 topic
docker exec -i redpanda rpk topic produce events.stage1.fast.v1 <<EOF
{
  "schema_version": "stage1_event.v1",
  "event_id": "test-001",
  "event_time_utc": "2024-01-01T12:00:00Z",
  "source_type": "rss",
  "source_name": "bloomberg",
  "canonical_url": "https://example.com/test",
  "lang": "en",
  "normalized_text": "Apple announces record Q4 earnings with revenue of $89.5 billion, up 12.5%. CEO Tim Cook expressed satisfaction. iPhone sales increased 15% while profit margin reached 42%.",
  "normalized_text_hash": "test123",
  "dedup_key": "test-001-dedup",
  "triage_score_stage1": 75.0,
  "triage_bucket": "fast",
  "symbols_candidates": ["AAPL"]
}
EOF

# 2. Consume triaged output
docker exec redpanda rpk topic consume events.triaged.v1 --num 1
```

## Prometheus Metrics

### Counters
- `triage_stage2_events_consumed_total`: Total events consumed
- `triage_stage2_events_triaged_total{priority}`: Events triaged by priority
- `triage_stage2_events_failed_total{reason}`: Failed events by reason
- `triage_stage2_dlq_total`: Events sent to DLQ
- `triage_stage2_entities_extracted_total{type}`: Entities extracted by type

### Histograms
- `triage_stage2_processing_duration_seconds`: Processing time per event
- `triage_stage2_score_distribution`: Triage score distribution
- `triage_stage2_sentiment_score`: Sentiment score distribution

### Gauges
- `triage_stage2_last_success_timestamp`: Last successful processing timestamp
- `triage_stage2_sentiment_mean`: Rolling mean sentiment
- `triage_stage2_market_regime`: Current market regime (0=CALM, 1=NORMAL, 2=STRESS)
- `triage_stage2_load_regime`: Current load regime (0=LOW, 1=NORMAL, 2=HIGH)

## Troubleshooting

### No events in output topic
1. Check Stage 1 is producing:
   ```bash
   docker exec redpanda rpk topic consume events.stage1.fast.v1 --num 1
   ```
2. Check service health:
   ```bash
   curl http://localhost:8007/health
   ```
3. Check logs:
   ```bash
   docker logs triage-stage2 --tail 100
   ```

### High latency (> 1s)
1. Reduce FinBERT batch size in config
2. Check CPU usage
3. Consider GPU for FinBERT inference

### All events go to DLQ
1. Check DLQ topic:
   ```bash
   docker exec redpanda rpk topic consume events.triaged.dlq.v1 --num 1
   ```
2. Verify input schema matches Stage 1 output
3. Check logs for NLP model errors

### Missing tickers
1. Add ticker to `config/tickers_whitelist.csv`
2. Lower confidence threshold in config:
   ```yaml
   tickers:
     confidence_threshold: 0.50
   ```

## Performance

**Targets**:
- Throughput: 100k events/day
- Latency p95: < 500ms
- DLQ Rate: < 1%

**Bottlenecks**:
- FinBERT inference: 100-300ms (use batching)
- spaCy NER: 20-50ms
- Kafka I/O: 10-30ms

**Optimization**:
- Batch FinBERT inference (8-16 events)
- Async Kafka I/O
- Cache VIX and whitelist

## References

- [spaCy Documentation](https://spacy.io/)
- [FinBERT Model](https://huggingface.co/ProsusAI/finbert)
- [User Documentation](../../docs/triage_stage2.md)
- [Task Completion](../../TASK_2.12_COMPLETE.md)
