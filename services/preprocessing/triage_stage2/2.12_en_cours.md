# Triage Stage 2 (NLP) - Implementation Guide

## Overview
This service consumes events from Stage 1 (FAST/STANDARD buckets) and enriches them with NLP:
- spaCy NER for entities (ORG, PERSON, MONEY, PERCENT)
- FinBERT for financial sentiment analysis
- Advanced scoring (0-100) with explainable reasons
- Adaptive thresholds based on market regime and pipeline load

## Current Implementation Status

### âœ… Completed
- [x] Schema `triaged_event.v1.json` with all required fields
- [x] Sample valid event
- [x] Configuration file `config/triage_stage2.yaml`
- [x] Tickers whitelist CSV
- [x] Docker requirements.txt with NLP dependencies
- [x] Dockerfile with spaCy models download
- [x] Topics added to init-topics.sh

### ðŸš§ In Progress (app.py skeleton created)
- [ ] Full NLP pipeline implementation
- [ ] FinBERT sentiment analysis
- [ ] Ticker validation logic
- [ ] Market regime detection
- [ ] Load regime detection
- [ ] Adaptive threshold calculation
- [ ] Prometheus metrics
- [ ] Health endpoint
- [ ] Integration tests

## Architecture

```
Input: events.stage1.fast.v1 + events.stage1.standard.v1
  â†“
[Load Config + Models]
  â†“
[spaCy NER] â†’ entities (ORG, PERSON, MONEY, PERCENT)
  â†“
[FinBERT] â†’ sentiment (score -1 to +1, confidence)
  â†“
[Ticker Validation] â†’ validate against whitelist
  â†“
[Scoring Engine] â†’ 0-100 score + reasons
  â†“
[Regime Detection] â†’ market + load regimes
  â†“
[Threshold Adjustment] â†’ adaptive P0/P1/P2/P3
  â†“
Output: events.triaged.v1 (or DLQ on error)
```

## Key Components

### 1. NLP Pipeline
- **spaCy NER**: Extract entities from text
  - ORG, PERSON for company/people identification
  - MONEY, PERCENT from model or regex fallback
- **FinBERT**: Financial sentiment model
  - Model: `ProsusAI/finbert`
  - Batch inference for performance (batch_size=8)
  - Max length: 512 tokens
  - Output: score âˆˆ [-1,1], confidence âˆˆ [0,1]

### 2. Scoring System (0-100)
Components:
- Keywords (0-30): Earnings, SEC, Fed, merger, bankruptcy, security
- Source Quality (0-25): Inherited from Stage 1 or config
- Ticker Confidence (0-20): Based on whitelist validation
- Entity Strength (0-10): Number and confidence of entities
- Sentiment Impact (0-15): |sentiment_score| Ã— confidence

### 3. Reasons (Explainability)
All scoring decisions must add tags to `triage_reasons`:
- HIGH_SOURCE_QUALITY, LOW_SOURCE_QUALITY
- HAS_VALID_TICKER, NO_TICKER
- KEYWORD_EARNINGS, KEYWORD_REGULATION, KEYWORD_MACRO, etc.
- STRONG_SENTIMENT, WEAK_SENTIMENT, LOW_SENTIMENT_CONF
- STRONG_ENTITIES, WEAK_ENTITIES, NER_EMPTY
- SHORT_TEXT, LONG_TEXT
- STRESS_REGIME_BOOST, HIGH_LOAD_PENALTY

### 4. Adaptive Thresholds

**Baseline:**
- P0: score â‰¥ 80
- P1: score â‰¥ 60
- P2: score â‰¥ 40
- P3: score < 40

**Market Regime Adjustments:**
- STRESS: T0-=10, T1-=10, T2-=10 (more P0/P1)
- NORMAL: no adjustment
- CALM: T0+=5, T1+=5, T2+=5 (fewer P0/P1)

**Load Regime Adjustments:**
- HIGH_LOAD: T0+=5, T1+=5, T2+=5 (push to P3)
- NORMAL_LOAD: no adjustment
- LOW_LOAD: T0-=3, T1-=3, T2-=3

### 5. Regime Detection

**Market Regime:**
- VIX â‰¥ 25 â†’ STRESS
- VIX < 12 â†’ CALM
- 12 â‰¤ VIX < 25 â†’ NORMAL
- Fallback: SPY 30D volatility

**Load Regime:**
- Consumer lag > 5000 OR p95 latency > 500ms OR DLQ rate > 5% â†’ HIGH_LOAD
- Consumer lag > 1000 OR p95 latency > 200ms OR DLQ rate > 1% â†’ NORMAL_LOAD
- Otherwise â†’ LOW_LOAD

## Metrics (Prometheus)

### Counters
- `triage_stage2_events_consumed_total`
- `triage_stage2_events_triaged_total{priority="P0|P1|P2|P3"}`
- `triage_stage2_events_failed_total{reason="..."}` 
- `triage_stage2_dlq_total`
- `triage_stage2_entities_extracted_total{type="ORG|PERSON|..."}`

### Histograms
- `triage_stage2_processing_duration_seconds`
- `triage_stage2_score_distribution`
- `triage_stage2_sentiment_score`

### Gauges
- `triage_stage2_last_success_timestamp`
- `triage_stage2_sentiment_mean` (rolling average)
- `triage_stage2_market_regime` (0=CALM, 1=NORMAL, 2=STRESS)
- `triage_stage2_load_regime` (0=LOW, 1=NORMAL, 2=HIGH)

## Grafana Dashboard

Panels needed:
1. **Throughput**: Input rate vs output rate
2. **Latency**: p95 processing time
3. **Priority Distribution**: Pie chart P0/P1/P2/P3
4. **DLQ Rate**: Percentage of events to DLQ
5. **Score Distribution**: Histogram of triage scores
6. **Sentiment Drift**: Mean sentiment over time
7. **Reason Distribution**: Top 10 triage_reasons
8. **Regimes**: Market + Load regime indicators

## Testing

### Integration Test
1. Inject 5 diverse events:
   - FR event with keywords
   - EN event with ticker + sentiment
   - Event without entities (LOW entities)
   - High-impact event (earnings + ticker)
   - Low-quality event (reddit unverified)

2. Verify outputs in `events.triaged.v1`:
   - Schema validation passes
   - Priority assigned (P0-P3)
   - At least 1 event has entities
   - All events have sentiment + confidence
   - Thresholds and regime logged

## Next Steps

1. Complete `app.py` implementation (~1000 lines)
2. Add to docker-compose.yml
3. Update Prometheus scrape config
4. Create Grafana dashboard JSON
5. Write integration tests
6. Write documentation (docs/triage_stage2.md)

## File Structure

```
services/preprocessing/triage_stage2/
â”œâ”€â”€ app.py              # Main application (~1000 lines)
â”œâ”€â”€ Dockerfile          # âœ… Created
â”œâ”€â”€ requirements.txt    # âœ… Created
â””â”€â”€ README.md           # This file

config/
â”œâ”€â”€ triage_stage2.yaml  # âœ… Created
â””â”€â”€ tickers_whitelist.csv # âœ… Created

schemas/
â”œâ”€â”€ triaged_event.v1.json # âœ… Created
â””â”€â”€ samples/
    â””â”€â”€ triaged_event_valid.json # âœ… Created
```

## Configuration

All configuration is in `config/triage_stage2.yaml`. Key sections:
- `keywords`: Impact and weak keywords
- `source_quality`: Per-source reliability scores
- `scoring`: Weights and thresholds
- `thresholds`: Baseline P0/P1/P2/P3 + regime adjustments
- `market_regime`: VIX thresholds
- `load_regime`: Lag/latency/DLQ thresholds
- `nlp`: spaCy models, FinBERT settings
- `tickers`: Whitelist file path

## Running Locally

```bash
# Build service
cd services/preprocessing/triage_stage2
docker build -t triage-stage2 .

# Run with docker-compose
cd ../../..
docker compose --profile apps --profile observability up -d triage-stage2

# Check health
curl http://localhost:8007/health

# Check metrics
curl http://localhost:8007/metrics | grep triage_stage2

# View logs
docker compose logs -f triage-stage2
```

## Performance Targets

- Throughput: 100k events/day (~1.16 events/sec avg, ~10 events/sec peak)
- Latency p95: < 500ms per event
- DLQ rate: < 1%
- Sentiment model batch size: 8 (tune based on CPU/GPU)
